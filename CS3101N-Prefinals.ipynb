{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "import numpy as np\n",
    "\n",
    "# Data Processing\n",
    "def read_file(file) -> list:\n",
    "    with open(file) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    attr = contents[2 : contents.index(\"@data\\n\") - 1]\n",
    "    data = contents[contents.index(\"@data\\n\") + 1 :]\n",
    "\n",
    "    return attr, data\n",
    "\n",
    "\n",
    "def parse_data(attr, data) -> list:\n",
    "    obj_list = []\n",
    "    for item in data:\n",
    "        vals = item.strip().split(\",\")\n",
    "        dct = {key: val if val != \"m\" else None for key, val in zip(attr, vals)}\n",
    "        obj_list.append(dct)\n",
    "\n",
    "    return obj_list\n",
    "\n",
    "\n",
    "def interpolation(obj_list) -> list:\n",
    "    for i in range(1, len(obj_list) - 1):\n",
    "        for key, value in obj_list[i].items():\n",
    "            if (\n",
    "                value is None\n",
    "                and obj_list[i - 1][key] is not None\n",
    "                and obj_list[i + 1][key] is not None\n",
    "            ):\n",
    "                obj_list[i][key] = (\n",
    "                    float(obj_list[i - 1][key]) + float(obj_list[i + 1][key])\n",
    "                ) / 2\n",
    "\n",
    "    return obj_list\n",
    "\n",
    "\n",
    "def convert_to_matrix(obj_list) -> list:\n",
    "    return [[row[attr] for row in obj_list] for attr in list(obj_list[0].keys())[2:]]\n",
    "\n",
    "\n",
    "def calculate_mean(col):\n",
    "    return sum(col) / len(col)\n",
    "\n",
    "\n",
    "def calculate_std_dev(mean, col):\n",
    "    if len(col) > 1:\n",
    "        variance = sum((x - mean) ** 2 for x in col)\n",
    "        std_dev = (variance / len(col)) ** 0.5\n",
    "        return std_dev\n",
    "    return 0\n",
    "\n",
    "\n",
    "def standardize(matrix) -> list:\n",
    "    for i in range(2, len(matrix[0])):\n",
    "        col = [float(row[i]) for row in matrix if row[i] is not None]\n",
    "\n",
    "        if len(set(col)) == 1:\n",
    "            continue\n",
    "\n",
    "        mean = calculate_mean(col)\n",
    "        std_dev = calculate_std_dev(mean, col)\n",
    "\n",
    "        matrix = [\n",
    "            [(float(cell) - mean) / std_dev if cell is not None else 0 for cell in row]\n",
    "            for row in matrix\n",
    "        ]\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def calculate_covariance(row, col) -> float:\n",
    "    size = len(row)\n",
    "    mean_row = calculate_mean(row)\n",
    "    mean_col = calculate_mean(col)\n",
    "    return sum((row[i] - mean_row) * (col[i] - mean_col) for i in range(size)) / (\n",
    "        size - 1\n",
    "    )\n",
    "\n",
    "\n",
    "def covariance(matrix) -> list:\n",
    "    size = len(matrix[0])\n",
    "    covar_matrix = [[0] * size for _ in range(size)]\n",
    "\n",
    "    for i in range(size):\n",
    "        for j in range(i, size):\n",
    "            x = [row[i] for row in matrix]\n",
    "            y = [row[j] for row in matrix]\n",
    "            covar_matrix[i][j] = calculate_covariance(x, y)\n",
    "\n",
    "    return covar_matrix\n",
    "\n",
    "\n",
    "def transpose_matrix(matrix) -> list:\n",
    "    return [[j[i] for j in matrix] for i in range(len(matrix[0]))]\n",
    "\n",
    "\n",
    "def dot_product(a, b) -> list:\n",
    "    return sum(float(x) * float(y) for x, y in zip(a, b))\n",
    "\n",
    "\n",
    "def matrix_multiplication(a, b):\n",
    "    return [[dot_product(row, col) for col in b] for row in a]\n",
    "\n",
    "\n",
    "def power_iteration(matrix, n=1000):\n",
    "    n_rows = len(matrix)\n",
    "    n_cols = len(matrix[0])\n",
    "    vector = np.random.rand(n_cols)\n",
    "\n",
    "    for _ in range(n):\n",
    "        vector = np.dot(matrix, vector)\n",
    "        magnitude = np.linalg.norm(vector)\n",
    "        vector /= magnitude\n",
    "\n",
    "    return magnitude, vector\n",
    "\n",
    "\n",
    "def pca(matrix, n):\n",
    "    covar_matrix = covariance(matrix)\n",
    "    n_features = len(matrix[0])\n",
    "\n",
    "    eigenvalues, eigenvectors = [], []\n",
    "\n",
    "    for _ in range(n):\n",
    "        eigenvalue, eigenvector = power_iteration(covar_matrix)\n",
    "        eigenvalues.append(eigenvalue)\n",
    "        eigenvectors.append(eigenvector)\n",
    "\n",
    "        deflated_matrix = [\n",
    "            [eigenvalue * v1 * v2 for v1, v2 in zip(eigenvectors[-1], eigenvectors[-1])]\n",
    "            for _ in range(len(covar_matrix))\n",
    "        ]\n",
    "        covar_matrix = [\n",
    "            [\n",
    "                covar_matrix[i][j] - deflated_matrix[i][j]\n",
    "                for j in range(len(covar_matrix[0]))\n",
    "            ]\n",
    "            for i in range(len(covar_matrix))\n",
    "        ]\n",
    "\n",
    "    return matrix_multiplication(matrix, transpose_matrix(eigenvectors[:n]))\n",
    "\n",
    "\n",
    "def svd(matrix):\n",
    "    matrix = [\n",
    "        [float(val) if val != None else float(0) for val in row] for row in matrix\n",
    "    ]\n",
    "\n",
    "    return np.linalg.svd(matrix, full_matrices=False)\n",
    "\n",
    "\n",
    "attr, data = read_file(\"./V4 data/2020.arff\")\n",
    "parsedData = parse_data(attr, data)\n",
    "interpolatedData = interpolation(parsedData)\n",
    "\n",
    "matrix = convert_to_matrix(interpolatedData)\n",
    "\n",
    "standardizedData = standardize(matrix)\n",
    "n_components = 2\n",
    "for row in pca(standardizedData, n_components):\n",
    "    print(row)\n",
    "\n",
    "for row in svd(standardizedData):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn pandas\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "matrix = [[float(val) if val != None else float(0) for val in row] for row in matrix]\n",
    "df = pd.DataFrame(np.matrix([[float(cell) for cell in j] for j in matrix]))\n",
    "df = pd.DataFrame(np.matrix(matrix))\n",
    "df_std = (df - df.mean()) /(df.std())\n",
    "pca = PCA(n_components=2)\n",
    "pc = pca.fit_transform(df_std)\n",
    "pdf = pd.DataFrame(data=pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "There are issues with data preprocessing that I had encountered as well as coding FROM SCRATCH the processes themselves that deal with PCA and SVD. Based from the code using external libraries like Numpy, Pandas, and Sklearn, I had noticed they were more efficient and easier.\n",
    "\n",
    "In short, I messed up in data preprocessing and properly doing the calculations which made the results vastly different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
